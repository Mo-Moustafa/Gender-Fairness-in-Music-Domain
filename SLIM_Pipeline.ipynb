{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cadc9208",
   "metadata": {},
   "source": [
    "# Neccessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e10d9e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "from Data_Splitter import build_data, create_user_track_matrix\n",
    "from Fairness_Metrics import compute_recGap, compute_compounding_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771cf053",
   "metadata": {},
   "source": [
    "# SLIM Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae8e5662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_slim(user_track_matrix, user_gender_map, female_weight=1.0, alpha=1e-3, l1_ratio=0.01, max_iter=1000, tol=1e-4):\n",
    "    \"\"\"\n",
    "    Train a SLIM model with sample weights that prioritize female users.\n",
    "    \n",
    "    Parameters:\n",
    "        user_track_matrix : pandas DataFrame (rows: users, columns: items)\n",
    "        user_gender_map   : dict mapping user_id to gender (e.g., {'user123': 'female', ...})\n",
    "        female_weight     : the weight factor to apply to female users.\n",
    "        alpha, l1_ratio, max_iter, tol : parameters for the ElasticNet solver.\n",
    "        \n",
    "    Returns:\n",
    "        W : the learned SLIM weight matrix (n_items x n_items) with zeros on the diagonal.\n",
    "    \"\"\"\n",
    "    # Convert the user-track interaction matrix to a dense array.\n",
    "    X = user_track_matrix.values.astype(float)  # shape: (n_users, n_items)\n",
    "    n_users, n_items = X.shape\n",
    "    W = np.zeros((n_items, n_items))\n",
    "    \n",
    "    # Create a sample weight vector for each user based on gender.\n",
    "    sample_weights = np.array([\n",
    "        female_weight if user_gender_map.get(user, 'male') == 'female' else 1.0\n",
    "        for user in user_track_matrix.index\n",
    "    ])\n",
    "    \n",
    "    # Train one model for each item.\n",
    "    for j in tqdm(range(n_items), desc=\"Training items\"):\n",
    "        # Remove column j from predictors.\n",
    "        X_others = np.delete(X, j, axis=1)\n",
    "        y = X[:, j]\n",
    "        # Set up the ElasticNet model.\n",
    "        model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, fit_intercept=False,\n",
    "                            positive=True, max_iter=max_iter, tol=tol)\n",
    "        # Here we pass the sample_weights. Note that support for sample_weight in ElasticNet\n",
    "        # depends on your scikit-learn version.\n",
    "        model.fit(X_others, y, sample_weight=sample_weights)\n",
    "        coefs = model.coef_\n",
    "        \n",
    "        # Rebuild the full coefficient vector for the j-th column.\n",
    "        w_j = np.zeros(n_items)\n",
    "        w_j[:j] = coefs[:j]\n",
    "        w_j[j] = 0  # ensure diagonal is zero\n",
    "        w_j[j+1:] = coefs[j:]\n",
    "        W[:, j] = w_j\n",
    "        \n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70855dab",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54698e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_for_user_slim(W, user_id, user_track_matrix, track_list, top_n=10):\n",
    "    \"\"\"\n",
    "    For a given user, generate recommendations using the SLIM weight matrix.\n",
    "    The prediction scores for a user are computed as:\n",
    "        scores = user_vector dot W\n",
    "    Items the user already interacted with are excluded from the recommendation list.\n",
    "    \n",
    "    Parameters:\n",
    "        W                : SLIM weight matrix (n_items x n_items)\n",
    "        user_id          : user identifier\n",
    "        user_track_matrix: pandas DataFrame (users x items)\n",
    "        track_list       : list of track IDs corresponding to the columns of user_track_matrix/W\n",
    "        top_n            : number of recommendations to return\n",
    "\n",
    "    Returns:\n",
    "        recommended_items: list of recommended track IDs\n",
    "    \"\"\"\n",
    "    if user_id not in user_track_matrix.index:\n",
    "        return []\n",
    "    \n",
    "    # Get the binary interaction vector for the user.\n",
    "    user_vector = user_track_matrix.loc[user_id].values.astype(float)   # shape: (n_items,)\n",
    "    scores = np.dot(user_vector, W)  # predicted scores for each item\n",
    "    \n",
    "    # Exclude items already seen by setting their score to -infinity.\n",
    "    user_history = set(user_track_matrix.loc[user_id][user_track_matrix.loc[user_id] > 0].index)\n",
    "    for idx, track in enumerate(track_list):\n",
    "        if track in user_history:\n",
    "            scores[idx] = -np.inf\n",
    "\n",
    "    # Get the indices of the top_n scores.\n",
    "    recommended_indices = np.argsort(scores)[::-1][:top_n]\n",
    "    recommended_tracks = [track_list[i] for i in recommended_indices if scores[i] != -np.inf]\n",
    "    \n",
    "    return recommended_tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf1e7f4",
   "metadata": {},
   "source": [
    "# Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2da381db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_at_k(relevances, k):\n",
    "    \"\"\"\n",
    "    Compute NDCG@k given a list of binary relevance scores.\n",
    "    \"\"\"\n",
    "    relevances = np.asfarray(relevances)[:k]\n",
    "    if relevances.size == 0:\n",
    "        return 0.0\n",
    "    discounts = np.log2(np.arange(2, relevances.size + 2))\n",
    "    dcg = np.sum(relevances / discounts)\n",
    "    ideal_relevances = np.sort(relevances)[::-1]\n",
    "    idcg = np.sum(ideal_relevances / discounts)\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "def evaluate_ndcg_slim(W, df, holdout_df, user_track_matrix, track_list, top_n=10):\n",
    "    \"\"\"\n",
    "    Evaluate recommendations using NDCG@k for each user in a holdout set.\n",
    "    \n",
    "    Parameters:\n",
    "      W                : SLIM weight matrix.\n",
    "      df               : Original DataFrame (assumes a 'gender' column exists).\n",
    "      holdout_df       : DataFrame with ground-truth interactions.\n",
    "      user_track_matrix: Training user–item matrix.\n",
    "      track_list       : List of track IDs.\n",
    "      top_n            : Number of recommendations.\n",
    "      \n",
    "    Returns:\n",
    "      overall_ndcg   : Average NDCG@top_n over all users.\n",
    "      ndcg_by_gender : Dictionary of average NDCG scores split by gender.\n",
    "    \"\"\"\n",
    "    # Map each user to his/her ground-truth holdout items.\n",
    "    user_holdout = holdout_df.groupby('user_id')['track_id'].apply(set).to_dict()\n",
    "    # Extract user attributes (like gender).\n",
    "    user_gender = df.set_index('user_id')['gender'].to_dict()\n",
    "    \n",
    "    ndcg_scores = {}\n",
    "    ndcg_by_gender = {}\n",
    "    \n",
    "    for user, true_items in user_holdout.items():\n",
    "        recs = get_recommendations_for_user_slim(W, user, user_track_matrix, track_list, top_n=top_n)\n",
    "        relevances = [1 if rec in true_items else 0 for rec in recs]\n",
    "        ndcg = ndcg_at_k(relevances, top_n)\n",
    "        ndcg_scores[user] = ndcg\n",
    "        \n",
    "        gender = user_gender.get(user, 'unknown')\n",
    "        ndcg_by_gender.setdefault(gender, []).append(ndcg)\n",
    "    \n",
    "    overall_ndcg = np.mean(list(ndcg_scores.values())) if ndcg_scores else 0.0\n",
    "    avg_ndcg_by_gender = {g: np.mean(scores) for g, scores in ndcg_by_gender.items()}\n",
    "\n",
    "    print(\"\\nSet Evaluation:\")\n",
    "    print(f\"Overall NDCG@{top_n}: {overall_ndcg:.4f}\")\n",
    "    print(\"NDCG by gender:\", avg_ndcg_by_gender)\n",
    "    \n",
    "    return overall_ndcg, avg_ndcg_by_gender\n",
    "\n",
    "def grid_search_validation_slim(user_track_matrix, track_list, df, val_holdout_df,\n",
    "                                        user_gender_map, female_weight, candidate_alphas, \n",
    "                                        fixed_l1_ratio=0.01, top_n=10):\n",
    "    \"\"\"\n",
    "    Performs grid search over candidate alpha values.\n",
    "    \n",
    "    For each alpha, the SLIM model is trained and evaluated on the validation holdout set using NDCG.\n",
    "    Returns:\n",
    "        best_alpha  : The alpha value that produced the highest overall NDCG.\n",
    "        best_ndcg   : The best NDCG value.\n",
    "        grid_results: A list of tuples (alpha, overall_ndcg).\n",
    "    \"\"\"\n",
    "    best_ndcg = -1.0\n",
    "    best_alpha = None\n",
    "    grid_results = []\n",
    "    \n",
    "    for alpha in candidate_alphas:\n",
    "        W_candidate = train_slim(user_track_matrix, user_gender_map, female_weight=female_weight,\n",
    "                                    alpha=alpha, l1_ratio=fixed_l1_ratio)\n",
    "        overall_ndcg_val, _ = evaluate_ndcg_slim(W_candidate, df, val_holdout_df, user_track_matrix, track_list, top_n=top_n)\n",
    "        grid_results.append((alpha, overall_ndcg_val))\n",
    "        print(f\"alpha: {alpha} => NDCG: {overall_ndcg_val:.4f}\")\n",
    "        if overall_ndcg_val > best_ndcg:\n",
    "            best_ndcg = overall_ndcg_val\n",
    "            best_alpha = alpha\n",
    "    print(\"\\nBest alpha:\", best_alpha)\n",
    "    print(\"Best overall NDCG on validation set:\", best_ndcg)\n",
    "    return best_alpha, best_ndcg, grid_results\n",
    "\n",
    "\n",
    "def compute_diversity_for_list(recommended_tracks, user_track_matrix, track_list, W):\n",
    "    \"\"\"\n",
    "    Compute intra-list diversity: average dissimilarity among all pairs of recommended tracks.\n",
    "    Dissimilarity is defined as 1 - cosine similarity. Here we retrieve the\n",
    "    item vectors (columns in the training matrix) for the recommended tracks.\n",
    "    \n",
    "    Parameters:\n",
    "      recommended_tracks: list of track IDs.\n",
    "      user_track_matrix: training user-item matrix.\n",
    "      track_list       : list of track IDs.\n",
    "      W                : weight matrix is not used directly here but one can also compute\n",
    "                         diversity on the basis of the original item vectors.\n",
    "    \n",
    "    Returns:\n",
    "      diversity score (float)\n",
    "    \"\"\"\n",
    "    if len(recommended_tracks) < 2:\n",
    "        return 0.0\n",
    "    \n",
    "    # For diversity we use the binary interaction vectors (or you could precompute item feature vectors)\n",
    "    indices = [track_list.index(t) for t in recommended_tracks if t in track_list]\n",
    "    # Extract the corresponding columns from the training matrix as item profiles.\n",
    "    # Transpose the matrix so each row is an item vector.\n",
    "    item_matrix = user_track_matrix.values.T  \n",
    "    vectors = item_matrix[indices]\n",
    "    \n",
    "    sim_matrix = cosine_similarity(vectors)\n",
    "    \n",
    "    # Compute average pairwise similarity (ignoring the diagonal).\n",
    "    sum_similarity = 0.0\n",
    "    count = 0\n",
    "    n = len(indices)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            sum_similarity += sim_matrix[i, j]\n",
    "            count += 1\n",
    "    \n",
    "    avg_similarity = sum_similarity / count if count > 0 else 0.0\n",
    "    return 1 - avg_similarity\n",
    "\n",
    "def evaluate_metrics_slim(W, df, holdout_df, user_track_matrix, track_list, top_n=10):\n",
    "    \"\"\"\n",
    "    Evaluate recommendation metrics (Recall, Coverage, Diversity) for the holdout set.\n",
    "    Also compute per-gender metrics using the user attributes from df.\n",
    "    \n",
    "    Parameters:\n",
    "      W                : SLIM weight matrix.\n",
    "      holdout_df       : DataFrame with ground-truth holdout interactions.\n",
    "      user_track_matrix: training user–item matrix.\n",
    "      track_list       : list of track IDs.\n",
    "      df               : original DataFrame (assumes a 'gender' column).\n",
    "      top_n            : number of recommendations.\n",
    "      \n",
    "    Returns:\n",
    "      overall_recall, overall_coverage, overall_diversity, and a dictionary of per-gender metrics.\n",
    "    \"\"\"\n",
    "    # Ground truth mapping.\n",
    "    user_holdout = holdout_df.groupby('user_id')['track_id'].apply(set).to_dict()\n",
    "    user_gender = df.set_index('user_id')['gender'].to_dict()\n",
    "    \n",
    "    recall_scores = {}\n",
    "    diversity_scores = {}\n",
    "    coverage_by_gender = {}\n",
    "    \n",
    "    for user, true_items in user_holdout.items():\n",
    "        recs = get_recommendations_for_user_slim(W, user, user_track_matrix, track_list, top_n=top_n)\n",
    "        # Recall@top_n computation.\n",
    "        recall = len(set(recs).intersection(true_items)) / len(true_items) if true_items else 0.0\n",
    "        recall_scores[user] = recall\n",
    "        \n",
    "        # Diversity computation.\n",
    "        diversity = compute_diversity_for_list(recs, user_track_matrix, track_list, W)\n",
    "        diversity_scores[user] = diversity\n",
    "        \n",
    "        gender = user_gender.get(user, 'unknown')\n",
    "        coverage_by_gender.setdefault(gender, set()).update(recs)\n",
    "    \n",
    "    overall_recall = np.mean(list(recall_scores.values()))\n",
    "    overall_diversity = np.mean(list(diversity_scores.values()))\n",
    "    overall_coverage = len(set().union(*(recs for recs in coverage_by_gender.values()))) / len(track_list)\n",
    "    \n",
    "    # Average per-gender metrics.\n",
    "    recall_by_gender = {}\n",
    "    diversity_by_gender = {}\n",
    "    coverage_metrics_by_gender = {}\n",
    "    \n",
    "    for user, rec in recall_scores.items():\n",
    "        gender = user_gender.get(user, 'unknown')\n",
    "        recall_by_gender.setdefault(gender, []).append(rec)\n",
    "    for user, div in diversity_scores.items():\n",
    "        gender = user_gender.get(user, 'unknown')\n",
    "        diversity_by_gender.setdefault(gender, []).append(div)\n",
    "    for gender, rec_set in coverage_by_gender.items():\n",
    "        coverage_metrics_by_gender[gender] = len(rec_set) / len(track_list)\n",
    "    \n",
    "    avg_recall_by_gender = {g: np.mean(scores) for g, scores in recall_by_gender.items()}\n",
    "    avg_diversity_by_gender = {g: np.mean(scores) for g, scores in diversity_by_gender.items()}\n",
    "\n",
    "    print(\"\\nEvaluation Metrics @ {}:\".format(top_n))\n",
    "    print(\"Overall Recall: {:.4f}\".format(overall_recall))\n",
    "    print(\"Recall by gender:\", avg_recall_by_gender)\n",
    "    print(\"\\nOverall Coverage: {:.4f}\".format(overall_coverage))\n",
    "    print(\"Coverage by gender:\", coverage_metrics_by_gender)\n",
    "    print(\"\\nOverall Diversity: {:.4f}\".format(overall_diversity))\n",
    "    print(\"Diversity by gender:\", avg_diversity_by_gender)\n",
    "    \n",
    "    gender_metrics = {\n",
    "        'recall': avg_recall_by_gender,\n",
    "        'coverage': coverage_metrics_by_gender,\n",
    "        'diversity': avg_diversity_by_gender\n",
    "    }\n",
    "    \n",
    "    return overall_recall, overall_coverage, overall_diversity, gender_metrics\n",
    "\n",
    "# Assuming recGap_CF_results, compute_recGap, and compute_compounding_factor are defined elsewhere:\n",
    "def recGap_CF_results(df, gender_metrics):\n",
    "    for key, value in gender_metrics.items():\n",
    "        print(f\"\\nFor the {key} metric\")\n",
    "        compute_recGap(value)\n",
    "        compute_compounding_factor(df, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69baa079",
   "metadata": {},
   "source": [
    "# Main Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df10e685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluate_SLIM(user_track_matrix, track_list, df, df_val_holdout, df_test_holdout,\n",
    "                    user_gender_map, female_weight=1.0, top_n=10):\n",
    "    \n",
    "    # # Define candidate alpha values.\n",
    "    # candidate_alphas = [1e-3, 1e-2, 1e-1]\n",
    "    best_alpha = 1e-3\n",
    "    \n",
    "    # best_alpha, best_ndcg, grid_results = grid_search_validation_slim(\n",
    "    #     user_track_matrix, track_list, df, df_val_holdout,\n",
    "    #     user_gender_map, female_weight, candidate_alphas, fixed_l1_ratio=0.01, top_n=top_n)\n",
    "    \n",
    "    # Retrain final SLIM model with best alpha.\n",
    "    W = train_slim(user_track_matrix, user_gender_map, female_weight=female_weight,\n",
    "                    alpha=best_alpha, l1_ratio=0.01)\n",
    "    \n",
    "    overall_ndcg_test, ndcg_by_gender_test = evaluate_ndcg_slim(W, df, df_test_holdout, user_track_matrix, track_list, top_n=top_n)\n",
    "    overall_recall, overall_coverage, overall_diversity, gender_metrics = evaluate_metrics_slim(W, df, df_test_holdout, user_track_matrix, track_list, top_n=top_n)\n",
    "    gender_metrics['ndcg'] = ndcg_by_gender_test \n",
    "    print(\"\\nOverall gender metrics:\", gender_metrics)\n",
    "    recGap_CF_results(df, gender_metrics)\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def build_and_evaluate_slim(df, female_weight=1.0):\n",
    "    # Prepare the data.\n",
    "    df_model_train, df_val_holdout, df_test_holdout = build_data(df)\n",
    "    user_track_matrix, _, track_list = create_user_track_matrix(df_model_train)\n",
    "    \n",
    "    # Create a mapping from user_id to gender (using the original dataframe).\n",
    "    user_gender_map = df.set_index('user_id')['gender'].to_dict()\n",
    "\n",
    "    # Train the SLIM model.\n",
    "    W = train_slim(user_track_matrix, user_gender_map, female_weight=female_weight, alpha=1e-3, l1_ratio=0.01)\n",
    "    \n",
    "    # Evaluate the SLIM model.\n",
    "    Evaluate_SLIM(user_track_matrix, track_list, df, df_val_holdout, df_test_holdout,\n",
    "                user_gender_map, female_weight=female_weight, top_n=10)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aab311f",
   "metadata": {},
   "source": [
    "# Running the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05de1538",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/LFM-1b-DemoBiasSub-10k.csv', header=0)\n",
    "df_SMOTE = pd.read_csv('data/LFM-1b-DemoBiasSub-10k-SMOTE.csv', header=0)\n",
    "df_resampled = pd.read_csv('data/LFM-1b-DemoBiasSub-10k-Resampled.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "750ade7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training items:   0%|          | 44/10000 [07:39<28:51:32, 10.44s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mbuild_and_evaluate_slim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 34\u001b[0m, in \u001b[0;36mbuild_and_evaluate_slim\u001b[1;34m(df, female_weight)\u001b[0m\n\u001b[0;32m     31\u001b[0m user_gender_map \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Train the SLIM model.\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m W \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_slim\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_track_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_gender_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfemale_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfemale_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Evaluate the SLIM model.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m Evaluate_SLIM(user_track_matrix, track_list, df, df_val_holdout, df_test_holdout,\n\u001b[0;32m     38\u001b[0m             user_gender_map, female_weight\u001b[38;5;241m=\u001b[39mfemale_weight, top_n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 35\u001b[0m, in \u001b[0;36mtrain_slim\u001b[1;34m(user_track_matrix, user_gender_map, female_weight, alpha, l1_ratio, max_iter, tol)\u001b[0m\n\u001b[0;32m     31\u001b[0m model \u001b[38;5;241m=\u001b[39m ElasticNet(alpha\u001b[38;5;241m=\u001b[39malpha, l1_ratio\u001b[38;5;241m=\u001b[39ml1_ratio, fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     32\u001b[0m                     positive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_iter\u001b[38;5;241m=\u001b[39mmax_iter, tol\u001b[38;5;241m=\u001b[39mtol)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Here we pass the sample_weights. Note that support for sample_weight in ElasticNet\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# depends on your scikit-learn version.\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_others\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m coefs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcoef_\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Rebuild the full coefficient vector for the j-th column.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\20115\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\20115\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:1077\u001b[0m, in \u001b[0;36mElasticNet.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1075\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1076\u001b[0m     this_Xy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1077\u001b[0m _, this_coef, this_dual_gap, this_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_alphas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43malphas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43mXy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthis_Xy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy_X\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoef_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1088\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_n_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1090\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpositive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpositive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1092\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# from here on **params\u001b[39;49;00m\n\u001b[0;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_offset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mselection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1101\u001b[0m coef_[k] \u001b[38;5;241m=\u001b[39m this_coef[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1102\u001b[0m dual_gaps_[k] \u001b[38;5;241m=\u001b[39m this_dual_gap[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\20115\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\20115\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697\u001b[0m, in \u001b[0;36menet_path\u001b[1;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[0;32m    683\u001b[0m     model \u001b[38;5;241m=\u001b[39m cd_fast\u001b[38;5;241m.\u001b[39menet_coordinate_descent_gram(\n\u001b[0;32m    684\u001b[0m         coef_,\n\u001b[0;32m    685\u001b[0m         l1_reg,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    694\u001b[0m         positive,\n\u001b[0;32m    695\u001b[0m     )\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m precompute \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m--> 697\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mcd_fast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menet_coordinate_descent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml1_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositive\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    701\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    702\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecompute should be one of True, False, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or array-like. Got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    703\u001b[0m         \u001b[38;5;241m%\u001b[39m precompute\n\u001b[0;32m    704\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "build_and_evaluate_slim(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2e8f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_counts = df['gender'].value_counts()\n",
    "total_users = len(df)\n",
    "p = np.array([g_count / total_users for g_count in g_counts])\n",
    "female_weight = p[0] / p[1]\n",
    "print(f\"weight adjustment = {female_weight:.2f}\")\n",
    "\n",
    "build_and_evaluate_slim(df, female_weight=female_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8645df40",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_and_evaluate_slim(df_SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a7eda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_and_evaluate_slim(df_resampled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
