{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92ba8b18",
   "metadata": {},
   "source": [
    "# Neccessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b57d8a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74088262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To handle the enormous events data without memory issues\n",
    "data_folder_path = 'Data/LFM-1B/'\n",
    "\n",
    "def reduce_memory(df):\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type == 'int64':\n",
    "            df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "        elif col_type == 'float64':\n",
    "            df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "        elif col_type == 'object':\n",
    "            num_unique = df[col].nunique()\n",
    "            num_total = len(df[col])\n",
    "            if num_unique / num_total < 0.5:\n",
    "                df[col] = df[col].astype('category')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6939db11",
   "metadata": {},
   "source": [
    "# Loading the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0582d132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the listening events data\n",
    "events = reduce_memory(pd.read_csv(data_folder_path + \"events.tsv\", sep=\"\\t\", header=0))\n",
    "# Filter needed columns only\n",
    "events = events[[\"user_id\",\"artist_id\", \"track_id\"]]\n",
    "# Aggregate play counts for each user-artist-track combination\n",
    "events = events.groupby([\"user_id\", \"artist_id\", \"track_id\"]).agg(play_count=(\"track_id\", \"count\")).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40feeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load demographic data about users\n",
    "demo = pd.read_csv(\"LFM-BeyMS\\creation\\LFM-1b_users.txt\", sep=\"\\t\", header=0)\n",
    "# Filter needed columns only\n",
    "demo = demo[[\"user_id\", \"country\", \"age\", \"gender\", \"registered_unixtime\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95613ed5",
   "metadata": {},
   "source": [
    "# Applying Filtering Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "050e4580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the first filtering step described in the paper to create the LFM-1b-DemoBias data\n",
    "demo_filtered = demo[demo['gender'].isin(['f', 'm'])]   # Filter to include only rows where gender is 'f' or 'm'\n",
    "\n",
    "# Merge the two datasets on 'user_id' using inner join to create the LFM_1b_DemoBias data\n",
    "LFM_1b_DemoBias = pd.merge(events, demo_filtered, on='user_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5201bea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove low-frequency interactions\n",
    "df_filtered = LFM_1b_DemoBias[LFM_1b_DemoBias['play_count'] >= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7802c1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# The second filtering step is to remove users and tracks with low interaction counts.\n",
    "\n",
    "''' \n",
    "In many real-world scenarios, applying one filter can affect the counts in the other.\n",
    "For example, after removing a user, some tracks might fall below the 5-user threshold.\n",
    "In such cases, an iterative approach ensures that both conditions remain valid.\n",
    "\n",
    "'''\n",
    "\n",
    "prev_shape = None\n",
    "while prev_shape != df_filtered.shape:\n",
    "    prev_shape = df_filtered.shape\n",
    "    \n",
    "    # Filter tracks: keep only those listened to by at least 5 unique users\n",
    "    track_user_counts = df_filtered.groupby('track_id')['user_id'].nunique()\n",
    "    valid_tracks = track_user_counts[track_user_counts >= 5].index\n",
    "    df_filtered = df_filtered[df_filtered['track_id'].isin(valid_tracks)]\n",
    "    \n",
    "    # Filter users: keep only those who listened to at least 5 unique tracks\n",
    "    user_track_counts = df_filtered.groupby('user_id')['track_id'].nunique()\n",
    "    valid_users = user_track_counts[user_track_counts >= 5].index\n",
    "    df_filtered = df_filtered[df_filtered['user_id'].isin(valid_users)]\n",
    "\n",
    "\n",
    "# Verify that each track has at least 5 unique users\n",
    "print(df_filtered.groupby('track_id')['user_id'].nunique().min())\n",
    "# Verify that each user has listened to at least 5 unique tracks\n",
    "print(df_filtered.groupby('user_id')['track_id'].nunique().min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc12189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39156\n",
      "gender\n",
      "m    265274\n",
      "f     84916\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Third step is to sample the data to create a manageable dataset for training.\n",
    "n_tracks = 10000    # We have reduced this number to 10k instead of 100k due to our limited computational resources.\n",
    "sampled_track_ids = df_filtered['track_id'].drop_duplicates().sample(n=n_tracks, random_state=42)\n",
    "df_sampled = df_filtered[df_filtered['track_id'].isin(sampled_track_ids)]\n",
    "\n",
    "print(df_sampled['user_id'].nunique())\n",
    "print(df_sampled['gender'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5556d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the sampled data to a CSV file\n",
    "df_sampled.to_csv(\"Data/LFM-1b-DemoBiasSub-10k.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
